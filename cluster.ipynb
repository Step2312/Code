{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://movie.douban.com/subject/34841067/comments?start=0&limit=20&status=P&sort=new_score', 'https://movie.douban.com/subject/34841067/comments?start=20&limit=20&status=P&sort=new_score', 'https://movie.douban.com/subject/34841067/comments?start=40&limit=20&status=P&sort=new_score', 'https://movie.douban.com/subject/34841067/comments?start=60&limit=20&status=P&sort=new_score', 'https://movie.douban.com/subject/34841067/comments?start=80&limit=20&status=P&sort=new_score', 'https://movie.douban.com/subject/34841067/comments?start=100&limit=20&status=P&sort=new_score', 'https://movie.douban.com/subject/34841067/comments?start=120&limit=20&status=P&sort=new_score', 'https://movie.douban.com/subject/34841067/comments?start=140&limit=20&status=P&sort=new_score', 'https://movie.douban.com/subject/34841067/comments?start=160&limit=20&status=P&sort=new_score', 'https://movie.douban.com/subject/34841067/comments?start=180&limit=20&status=P&sort=new_score']\n"
     ]
    },
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls: \u001b[38;5;66;03m#使用for循环分别获取每个页面的数据，保存到comments_list列表\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url\u001b[38;5;241m=\u001b[39murl,headers \u001b[38;5;241m=\u001b[39m dic_h)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m---> 14\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlxml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     ul \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     lis\u001b[38;5;241m=\u001b[39m ul\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Software\\anaconda\\envs\\test\\lib\\site-packages\\bs4\\__init__.py:248\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     builder_class \u001b[38;5;241m=\u001b[39m builder_registry\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a tree builder with the features you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Do you need to install a parser library?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(features))\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "from utils import readJSON\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import calinski_harabasz_score,silhouette_score,adjusted_rand_score\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]  #设置字体\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "\n",
    "def preprocess(path, sheet_name):\n",
    "    xzb = pd.read_excel(path, sheet_name=sheet_name)\n",
    "    xzb.drop(columns=['病案号'], inplace=True)\n",
    "    xzb.drop(labels=[1742, 1741], axis=0, inplace=True)\n",
    "    xzb.drop(labels=xzb[xzb['性别'].isna()].index, inplace=True)\n",
    "    xzb = xzb.sample(frac=1).astype(int)\n",
    "    y = xzb['证名']\n",
    "    X = xzb.drop(labels=['证名', '性别', '年龄'], axis=1)\n",
    "    id2feature = readJSON('./input/id2feature.json')\n",
    "    X.columns = id2feature.values()\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X, y)\n",
    "    X = pd.DataFrame(X, columns=scaler.feature_names_in_)\n",
    "    lsvc = LinearSVC(C=0.01, penalty='l1', dual=False, random_state=64).fit(X, y)\n",
    "    model = SelectFromModel(lsvc, prefit=True)\n",
    "    col = [c for c, i in zip(X.columns, model.get_support()) if not i]\n",
    "    X.drop(columns=col, inplace=True)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    data = pd.concat([pd.DataFrame(X), pd.DataFrame(y, columns=['证名'])], axis=1)\n",
    "    xqx = data[data['证名'] == 0]  # 621\n",
    "    xxyz = data[data['证名'] == 4]  # 547\n",
    "    xqx['证名'] = 0\n",
    "    xxyz['证名'] = 1\n",
    "    tmp = pd.concat([xqx, xxyz], axis=0).sample(frac=1).reset_index(drop=True)\n",
    "    X = tmp.drop(columns='证名')\n",
    "    y = tmp['证名']\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = preprocess(path='./input/心总表.xlsx', sheet_name='总表')\n",
    "# from sklearn.datasets import load_iris\n",
    "# X,y = load_iris(return_X_y=True)\n",
    "USE_Kmeans = True\n",
    "USE_DBSCAN = True\n",
    "USE_GMM  = True\n",
    "USE_AffinityPropagation = False\n",
    "USE_MeanShift = False\n",
    "USE_OPTICS = True\n",
    "USE_AgglomerativeClustering = True\n",
    "\n",
    "\n",
    "\n",
    "if USE_Kmeans:\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    # 肘部法\n",
    "    mean_distortions = []\n",
    "    for k in range(2, 9):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=1024)\n",
    "        kmeans.fit(X)\n",
    "        mean_distortions.append(kmeans.inertia_)\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, 8), mean_distortions, 'bx-')\n",
    "    plt.ylabel('inertia')  # Sum of squared distances of samples to their closest cluster center\n",
    "    plt.xlabel('K')\n",
    "    plt.title('KMeans-肘部法')\n",
    "    plt.show()\n",
    "    # 轮廓系数\n",
    "    for i in range(2,9):\n",
    "        kmeans = KMeans(n_clusters=i,random_state=1024)\n",
    "        kmeans_pred = kmeans.fit_predict(X)\n",
    "        sh_score = silhouette_score(X,kmeans_pred)\n",
    "        ch_score = calinski_harabasz_score(X,kmeans_pred)\n",
    "        arand_score = adjusted_rand_score(y,kmeans_pred)\n",
    "        mutual_score = metrics.adjusted_mutual_info_score(y,kmeans_pred)\n",
    "        homogeneity = metrics.homogeneity_score(y,kmeans_pred)\n",
    "        completeness = metrics.completeness_score(y,kmeans_pred)\n",
    "        v_measure_score  =metrics.v_measure_score(y,kmeans_pred)\n",
    "        fowlkes_mallows_score = metrics.fowlkes_mallows_score(y,kmeans_pred)\n",
    "        print(Counter(y))\n",
    "        print(f'kmeans cluster={i}:{Counter(kmeans_pred)},    CH指数={round(ch_score,2)},   轮廓系数={round(sh_score,2)},    ARI={round(arand_score)}     互信息={round(mutual_score)}   homogeneity={homogeneity}   completeness={completeness}     v_measure_score={v_measure_score}    fowlkes_mallows_score={fowlkes_mallows_score}')\n",
    "\n",
    "if USE_DBSCAN:\n",
    "    from sklearn.cluster import DBSCAN\n",
    "    from collections import Counter\n",
    "    eps, min_samples = 0.4,5\n",
    "    dbscan_pred = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(X)\n",
    "    print(f'DBSCAN',Counter(dbscan_pred))\n",
    "    n_clusters_ = len(set(dbscan_pred)) - (1 if -1 in dbscan_pred else 0)\n",
    "\n",
    "    sh_score = silhouette_score(X,kmeans_pred)\n",
    "    ch_score = calinski_harabasz_score(X,kmeans_pred)\n",
    "    arand_score = adjusted_rand_score(y,kmeans_pred)\n",
    "    mutual_score = metrics.adjusted_mutual_info_score(y,kmeans_pred)\n",
    "    homogeneity = metrics.homogeneity_score(y,kmeans_pred)\n",
    "    completeness = metrics.completeness_score(y,kmeans_pred)\n",
    "    v_measure_score  =metrics.v_measure_score(y,kmeans_pred)\n",
    "    fowlkes_mallows_score = metrics.fowlkes_mallows_score(y,kmeans_pred)\n",
    "    print(Counter(y))\n",
    "    print(f'kmeans cluster={i}:{Counter(kmeans_pred)},    CH指数={round(ch_score,2)},   轮廓系数={round(sh_score,2)},    ARI={round(arand_score)}     互信息={round(mutual_score)}   homogeneity={round(homogeneity,2)}   completeness={round(completeness,2)}     v_measure_score={round(v_measure_score,2)}    fowlkes_mallows_score={round(fowlkes_mallows_score,2)}')\n",
    "    # DBSCAN Counter({-1: 1168})\n",
    "    # DBSCAN:Counter({-1: 1163, 0: 5})   CH指数=3.44   轮廓系数=-0.06\n",
    "\n",
    "if USE_GMM:\n",
    "    from sklearn.mixture import GaussianMixture as GMM\n",
    "    for i in range(2,9):\n",
    "        gmm_pred = GMM(n_components=i,random_state=1024).fit_predict(X)\n",
    "        sh_score = silhouette_score(X,kmeans_pred)\n",
    "        ch_score = calinski_harabasz_score(X,kmeans_pred)\n",
    "        arand_score = adjusted_rand_score(y,kmeans_pred)\n",
    "        mutual_score = metrics.adjusted_mutual_info_score(y,kmeans_pred)\n",
    "        homogeneity = metrics.homogeneity_score(y,kmeans_pred)\n",
    "        completeness = metrics.completeness_score(y,kmeans_pred)\n",
    "        v_measure_score  =metrics.v_measure_score(y,kmeans_pred)\n",
    "        fowlkes_mallows_score = metrics.fowlkes_mallows_score(y,kmeans_pred)\n",
    "        print(Counter(y))\n",
    "        print(f'kmeans cluster={i}:{Counter(kmeans_pred)},    CH指数={round(ch_score,2)},   轮廓系数={round(sh_score,2)},    ARI={round(arand_score)}     互信息={round(mutual_score)}   homogeneity={round(homogeneity,2)}   completeness={round(completeness,2)}     v_measure_score={round(v_measure_score,2)}    fowlkes_mallows_score={round(fowlkes_mallows_score,2)}')\n",
    "        # GMM:Counter({1: 901, 0: 267})   CH指数=24.08   轮廓系数=0.18\n",
    "\n",
    "if USE_AffinityPropagation:\n",
    "    from sklearn.cluster import AffinityPropagation\n",
    "    import numpy as np\n",
    "    for i in np.arange(0.5,1,0.1):\n",
    "        AffinityPropagation_pred = AffinityPropagation(damping=i,random_state=1024).fit_predict(X)\n",
    "        sh_score = silhouette_score(X,kmeans_pred)\n",
    "        ch_score = calinski_harabasz_score(X,kmeans_pred)\n",
    "        arand_score = adjusted_rand_score(y,kmeans_pred)\n",
    "        mutual_score = metrics.adjusted_mutual_info_score(y,kmeans_pred)\n",
    "        homogeneity = metrics.homogeneity_score(y,kmeans_pred)\n",
    "        completeness = metrics.completeness_score(y,kmeans_pred)\n",
    "        v_measure_score  =metrics.v_measure_score(y,kmeans_pred)\n",
    "        fowlkes_mallows_score = metrics.fowlkes_mallows_score(y,kmeans_pred)\n",
    "        print(Counter(y))\n",
    "        print(f'kmeans cluster={i}:{Counter(kmeans_pred)},    CH指数={round(ch_score,2)},   轮廓系数={round(sh_score,2)},    ARI={round(arand_score)}     互信息={round(mutual_score)}   homogeneity={round(homogeneity,2)}   completeness={round(completeness,2)}     v_measure_score={round(v_measure_score,2)}    fowlkes_mallows_score={round(fowlkes_mallows_score,2)}')\n",
    "\n",
    "if USE_MeanShift:\n",
    "    from sklearn.cluster import MeanShift\n",
    "    meanshift_pred = MeanShift().fit_predict(X)\n",
    "    sh_score = silhouette_score(X,kmeans_pred)\n",
    "    ch_score = calinski_harabasz_score(X,kmeans_pred)\n",
    "    arand_score = adjusted_rand_score(y,kmeans_pred)\n",
    "    mutual_score = metrics.adjusted_mutual_info_score(y,kmeans_pred)\n",
    "    homogeneity = metrics.homogeneity_score(y,kmeans_pred)\n",
    "    completeness = metrics.completeness_score(y,kmeans_pred)\n",
    "    v_measure_score  =metrics.v_measure_score(y,kmeans_pred)\n",
    "    fowlkes_mallows_score = metrics.fowlkes_mallows_score(y,kmeans_pred)\n",
    "    print(Counter(y))\n",
    "    print(f'kmeans cluster={i}:{Counter(kmeans_pred)},    CH指数={round(ch_score,2)},   轮廓系数={round(sh_score,2)},    ARI={round(arand_score)}     互信息={round(mutual_score)}   homogeneity={round(homogeneity,2)}   completeness={round(completeness,2)}     v_measure_score={round(v_measure_score,2)}    fowlkes_mallows_score={round(fowlkes_mallows_score,2)}')\n",
    "\n",
    "if USE_OPTICS:\n",
    "    from sklearn.cluster import OPTICS\n",
    "    optics_pred = OPTICS(eps=8,min_samples=41).fit_predict(X)\n",
    "    n_clusters_ = len(set(optics_pred)) - (1 if -1 in optics_pred else 0)\n",
    "    sh_score = silhouette_score(X,kmeans_pred)\n",
    "    ch_score = calinski_harabasz_score(X,kmeans_pred)\n",
    "    arand_score = adjusted_rand_score(y,kmeans_pred)\n",
    "    mutual_score = metrics.adjusted_mutual_info_score(y,kmeans_pred)\n",
    "    homogeneity = metrics.homogeneity_score(y,kmeans_pred)\n",
    "    completeness = metrics.completeness_score(y,kmeans_pred)\n",
    "    v_measure_score  =metrics.v_measure_score(y,kmeans_pred)\n",
    "    fowlkes_mallows_score = metrics.fowlkes_mallows_score(y,kmeans_pred)\n",
    "    print(Counter(y))\n",
    "    print(f'kmeans cluster={i}:{Counter(kmeans_pred)},    CH指数={round(ch_score,2)},   轮廓系数={round(sh_score,2)},    ARI={round(arand_score)}     互信息={round(mutual_score)}   homogeneity={round(homogeneity,2)}   completeness={round(completeness,2)}     v_measure_score={round(v_measure_score,2)}    fowlkes_mallows_score={round(fowlkes_mallows_score,2)}')\n",
    "    # OPTICS:Counter({0: 1111, -1: 57})   CH指数=17.08   轮廓系数=0.46\n",
    "if USE_AgglomerativeClustering:\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    for i in range(2,9):\n",
    "        AgglomerativeClustering_pred = AgglomerativeClustering(n_clusters=i).fit_predict(X)\n",
    "        sh_score = silhouette_score(X,kmeans_pred)\n",
    "        ch_score = calinski_harabasz_score(X,kmeans_pred)\n",
    "        arand_score = adjusted_rand_score(y,kmeans_pred)\n",
    "        mutual_score = metrics.adjusted_mutual_info_score(y,kmeans_pred)\n",
    "        homogeneity = metrics.homogeneity_score(y,kmeans_pred)\n",
    "        completeness = metrics.completeness_score(y,kmeans_pred)\n",
    "        v_measure_score  =metrics.v_measure_score(y,kmeans_pred)\n",
    "        fowlkes_mallows_score = metrics.fowlkes_mallows_score(y,kmeans_pred)\n",
    "        print(Counter(y))\n",
    "        print(f'kmeans cluster={i}:{Counter(kmeans_pred)},    CH指数={round(ch_score,2)},   轮廓系数={round(sh_score,2)},    ARI={round(arand_score)}     互信息={round(mutual_score)}   homogeneity={round(homogeneity,2)}   completeness={round(completeness,2)}     v_measure_score={round(v_measure_score,2)}    fowlkes_mallows_score={round(fowlkes_mallows_score,2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 844, 2: 209, 1: 115})\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "urls=['https://movie.douban.com/subject/34841067/comments?start={}&limit=20&status=P&sort=new_score'.format(str(i)) for i in range(0, 200, 20)] #通过观察的url翻页的规律，使用for循环得到10个链接，保存到urls列表中\n",
    "print(urls)\n",
    "dic_h = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"}\n",
    "comments_list = [] #初始化用于保存短评的列表\n",
    "\n",
    "for url in urls: #使用for循环分别获取每个页面的数据，保存到comments_list列表\n",
    "    r = requests.get(url=url,headers = dic_h).text\n",
    "\n",
    "    soup = BeautifulSoup(r, 'lxml')\n",
    "    ul = soup.find('div',id=\"comments\")\n",
    "    lis= ul.find_all('p')\n",
    "\n",
    "    list2 =[]\n",
    "    for li in lis:\n",
    "        list2.append(li.find('span').string)\n",
    "    # print(list2)\n",
    "    comments_list.extend(list2)\n",
    "    time.sleep(random.randint(0,3)) # 暂停0~3秒\n",
    "\n",
    "with open('lhy_comments.txt', 'w', encoding='utf-8') as f: #使用with open()新建对象f\n",
    "    # 将列表中的数据循环写入到文本文件中\n",
    "    for i in comments_list:\n",
    "        f.write(i+\"\\n\") #写入数据\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "397224b3cdb3a23561542feed94c5cf45952f2aadda9fa59ec57fed9311c625f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
